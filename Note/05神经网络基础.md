# 神经网络基础

<center>
  by <a href="https://github.com/zhuozhiyongde">Arthals</a> / GPT4 / Claude 3 Opus
  <br/>
  blog: <a href="https://arthals.ink">Arthals' ink</a>
</center>

## 神经网络的基本概念

### 神经元模型

![neuron](https://cdn.arthals.ink/bed/2024/03/neuron-515f7ecbf9403a243bb103f403e1c33f.png)

神经元模型是神经网络的基本单元，它接收输入信号，对输入信号进行 **加权求和**，权重 / 参数（weight/parameter）的绝对值越大，则代表对应的输入 $x$ 对输出影响越大，然后通过激活函数处理，最后输出结果。

基于向量相乘的实现，分为列格式和行格式：

#### 列格式

$$
\begin{aligned}
{x} &= \begin{bmatrix}{x}_1 \\ {x}_2 \\ {x}_3\end{bmatrix} \quad {w} = \begin{bmatrix}{w}_1 \\ {w}_2 \\ {w}_3\end{bmatrix} \\
\\
z &= {w}^T{x} \\
&= \begin{bmatrix}{w}_1 \  {w}_2 \ {w}_3\end{bmatrix}\begin{bmatrix}{x}_1 \\ {x}_2 \\ {x}_3\end{bmatrix}
\end{aligned}
$$

在这种格式下，$x$ 的每个分量都是一个特征，$w$ 的每个分量都是对应特征的权重。$z$ 是一个标量。

#### 行格式

$$
\begin{aligned}
{x} &= \begin{bmatrix}{x}_1 \ {x}_2 \ {x}_3\end{bmatrix} \quad w=\begin{bmatrix}w_1\\w_2\\w_3\end{bmatrix} \\
\\
z &= {x}{w} \\
&= \begin{bmatrix}{x}_1 \ {x}_2 \ {x}_3\end{bmatrix}\begin{bmatrix}{w}_1 \\ {w}_2 \\ {w}_3\end{bmatrix}
\end{aligned}
$$

同列格式一样，这里 $x$ 的每个分量也都是一个特征，$w$ 的每个分量也都是对应特征的权重。$z$ 是一个标量。

不同点在于，这种格式在代码中更为常用，这是因为我们经常多个样本一起处理（mini-batch），通过将第一个维度（第 0 维）留给样本数，可以更方便的处理多个样本。

当然，我们也可以再加上偏置（bias） $b$，来增加模型的表达能力（改变原先必然过圆心的决策边界）：

![bias](https://cdn.arthals.ink/bed/2024/03/bias-53d8104351c3fc4b0df0f02b37661a77.png)

### 激活函数

激活函数（activation function）：对神经元的输出进行非线性变换，提供⾮线性性（non-linearity），增加神经网络的表达能力。

常用的激活函数及对应的公式、映射关系如下：

-   Sigmoid 函数
    -   公式：$f(x)=\frac{1}{1+e^{-x}}$
    -   映射关系：$(-\infty,+\infty) \rightarrow (0,1)$，输出值在 0 到 1 之间，用以表示概率
-   Tanh 函数
    -   公式：$f(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}=\frac{2}{1+e^{-2x}}$
    -   映射关系：$(-\infty,+\infty) \rightarrow (-1,1)$，输出值在 -1 到 1 之间，常用于回归任务
-   ReLU 函数
    -   公式：$f(x)=\max(0,x)$
    -   映射关系：$(-\infty,+\infty) \rightarrow (0,+\infty)$，最常用的分类函数，可以用于特征提取、简化网络优化（缓解梯度消失问题、偏导数好计算）
-   Leaky ReLU 函数
    -   公式：$f(x)=\max(\alpha x,x)$
    -   映射关系：$(-\infty,+\infty) \rightarrow (-\infty,+\infty)$，解决 ReLU 函数中负数部分输出为 0 的问题，其中的 $\alpha$ 是一个小的常数，如 0.01，在 Parametric ReLU 中，这个 $\alpha$ 是一个可学习的参数
-   Softmax 函数
    -   公式：$f(x_i)=\frac{e^{x_i}}{\sum_{j=1}^n e^{x_j}}$
    -   映射关系：$(-\infty,+\infty) \rightarrow (0,1)$，输出值在 0 到 1 之间，用以表示概率，使得所有激活值之和为 1

### 多层感知器（Multi-Layer Perceptron, MLP）

多层感知器是一种前馈神经网络，它由 **输入层**、**隐藏层**和**输出层** 组成。

相较于单层感知器的线性决策边界，多层感知器通过将多个单层感知器叠加，后一个层将原有层的输出值当做特征值来学习，也就是 “在原有特征的基础上，再次进行特征提取（变换）”，从而具有更好的表达能力。这能更好的解决现实中更复杂的问题。

![mlp](https://cdn.arthals.ink/bed/2024/03/mlp-c58ede3984dd3856c644ff2a69817a3b.png)

**注意，$a$ 代表的是激活函数的输出，之前的 $z$ 代表的是加权求和的结果。$a = f(z)$**

$$
a_k^l
$$

-   $l$ 代表层索引，$l=1,2,\cdots,L$，直接以输入值作为输入层可以写为 $x=a^0$
-   $k$ 代表神经元索引，$k=1,2,\cdots,K$

多层感知器可以进一步抽象成 Encoder-Decoder 模型，其中 Encoder 用于提取特征，Decoder 用于还原数据。

![encoder-decoder](https://cdn.arthals.ink/bed/2024/03/encoder-decoder-e4bf3f573ca28fb7681bbe7e17b82a35.png)

这个模型后续会在 RNN 和 Seq2Seq 中有所体现。现今大火的 Diffusion Model 也正是基于这个思想来设计的。在当前学习的全连接 MLP 中，我们可以简单的认为除输出层外的所有层都是 Encoder，输出层是 Decoder。

### 损失函数

损失函数（loss function）：用来量化网络预测的输出（predicted output）和给定训练数据输出（ground truth）之间的 **误差 (error，也称 loss value)**。

损失函数用来设定优化神经网络参数（如权重、偏置）的目标。

优化神经网络的过程，就是通过更新其参数来使得误差尽可能小。

梯度下降（gradient descent）是最常用的优化方法。

损失函数的选择：

首先，我们回忆一下之前我们是如何定义交叉熵的：

$$
\begin{aligned}
L_i&=-\log P(Y=y_i|X=x_i)
\end{aligned}
$$

这里的 $P(Y=y_i|X=x_i)$ 是指在给定输入 $x_i$ 的情况下，输出 $y_i$ 的概率。这个概率是由神经网络给出的，也就是 $P(Y=y_i|X=x_i)=f(x_i)$，其中 $f$ 是神经网络的输出函数。

#### 回归问题：均方误差损失函数（mean squared error loss function）

$$
\mathcal{L} = y\log(a) + (1 - y)\log(1 - a)\\
\mathcal{L} = \sum_{m=1}^{M} (y^m\log(a^m) + (1 - y^m)\log(1 - a^m))
$$

这是在二分类条件下的交叉熵损失函数。

这里：

-   $a$ 是神经网络的输出，也就是模型预测的分类概率。
-   $y$ 是真实值，也即标签
-   上标 $m$ 代表第 $m$ 个样本，而不是幂次。

由于 $y$ 是标签，所以 $y$ 和 $1-y$ 有一个取值为 0 另一个为 1，这被用于选择正确的损失项，当真实标签 $y^m=1$ 时，$y^m\log(a^m)$ 项用于计算损失；当 $y^m=0$ 时，$(1 - y^m)\log(1 - a^m)$ 项用于计算损失。

第一个式子为单个样本的损失函数，第二个式子为多个样本的损失函数。

> 使用 GPT4 生成的从头推导（符号可能有些不一样）
>
> 逻辑回归的损失函数是从最大似然估计（Maximum Likelihood Estimation, MLE）推导而来的。
>
> 给定一组数据，MLE 的目标是找到模型参数（在逻辑回归中是权重 $w$ 和偏差 $b$​），使得观察到的数据出现的概率（似然）最大。
>
> 对于逻辑回归，似然函数可以写为：
>
> $$
> L(\theta) = \prod_{i=1}^{m} P(y^{(i)} | x^{(i)}; \theta) = \prod_{i=1}^{m} a^{y^{(i)}}(1-a)^{1-y^{(i)}}
> $$
>
> 其中：
>
> -   $m$ 是样本数量，
> -   $y^{(i)}$ 是第 $i$ 个样本的真实类别，
> -   $x^{(i)}$ 是第 $i$ 个样本的特征，
> -   $a$ 是模型关于参数 $\theta$ （即权重和偏差）预测的概率，
> -   $\theta$ 是模型参数。
>
> 取对数似然，我们得到对数似然函数：
>
> $$
> \log L(\theta) = \sum_{i=1}^{m} y^{(i)} \log(a) + (1-y^{(i)}) \log(1-a)
> $$
>
> 在优化问题中，通常最小化负的对数似然，因此损失函数变为：
>
> $$
> J(\theta) = -\frac{1}{m}\sum_{i=1}^{m} [y^{(i)} \log(a) + (1-y^{(i)}) \log(1-a)]
> $$
>
> 这就是逻辑回归中常用的损失函数，也称为对数损失（Log Loss）或交叉熵损失（Cross-Entropy Loss）。

#### 分类问题：交叉熵损失函数（cross-entropy loss function）

公式是：

$$
\begin{aligned}
\mathcal{L}&=-\sum_{k=1}^K y_k\log(a_k)\\
\mathcal{L}&=-\frac{1}{M}\sum_{m=1}^M\sum_{k=1}^K y_k^m\log(a_k^m)
\end{aligned}
$$

这里：

-   $K$ 是类别的总数
-   $y_k$ 是一个独热编码向量，其中只有对应真实类别的那一项为 1，其余为 0
-   $a_k$ 是神经网络输出的概率预测，对应于类别 $k$
-   上标 $m$ 表示第 $m$ 个样本。

第一个式子为单个样本的损失函数，第二个式子为多个样本的损失函数。

### L 范数

$$
||x||_L = \left( \sum_{i=1}^n |x_i|^L \right)^{\frac{1}{L}}
$$

-   $L=1$ 时，称为 L1 范数，MAE（Mean Absolute Error，平均绝对误差）。用于衡量两个向量之前差别的大小
-   $L=2$ 时，称为 L2 范数，MSE（Mean Squared Error，均方误差）。⽤来衡量⽹络输出值 $a$ 和训练数据输出值 $y$ 的差别（MAE 也可以，区别在于 L2 范数对异常值更敏感）

### 优化

目的：给定网络 $f(x;\theta)$ 和损失函数 $L$ ，以获得好的参数 $\theta$，最小化损失函数 $\mathcal{L}$。

最常用的优化方法是梯度下降（gradient descent）。梯度下降的思想是通过不断迭代来更新参数，使得损失函数最小化。

#### 梯度下降

$$
w_j:=w_j-\alpha\frac{\partial\mathcal{L}}{\partial w_j}\quad w=[w_1,w_2,...]
$$

-   $\alpha$ 称为学习率（learning rate）
-   $\frac{\partial\mathcal{L}}{\partial w_j}$ 称为梯度（gradient），代表损失函数 $\mathcal{L}$ 对权重 $\partial w_j$ 的偏导数
-   $w_j$ 称为权重（weight），$j$ 代表权重的索引
-   $w$ 称为权重向量（weight vector）

![gradient_descent](https://cdn.arthals.ink/bed/2024/03/gradient_descent-b73c83420d33de3378c892d90822f0e0.png)

在更高的维度，可能无法很好的可视化这个过程，但是其思想是一样的。

无论有多少参数，我们只需要计算出梯度 $\frac{\partial\mathcal{L}}{\partial\theta}$ 即可优化每一个参数。

$$
\boldsymbol{\theta}:=\boldsymbol{\theta}-\alpha\frac{\partial\mathcal{L}}{\partial\boldsymbol{\theta}}
$$

#### 误差反向传播

误差反向传播（Backpropagation，BP）是一种用于训练神经网络的方法，其就是梯度下降的思想的具体实现。

误差反向传播，也就是利用链式法则来计算损失函数对参数的梯度的方法。为了计算对于每个参数的偏导数，我们首先计算每个神经元的中间结果 $\delta$，也就是损失函数 $L$ 对于神经网络中某一层的激活值 $z$ 的偏导数 $\delta=\frac{\partial L}{\partial z}$。

利用这个中间结果 $\delta$ ，我们可以计算损失函数对于每个参数 $\theta$ 的偏导数 $\frac{\partial L}{\partial \theta}$，即最终我们需要的梯度。进而通过这个梯度，我们可以调整参数 $\theta$ 来减少整个网络的损失。

![backpropagation](https://cdn.arthals.ink/bed/2024/03/backpropagation-9b5084997378e853a5c962b49ef11985.png)

图中展示了一个简化的神经网络结构，包含输入层、多个隐藏层和输出层。每一层都有多个神经元（用 $a$ 表示），它们之间通过权重（即参数 $\theta$）相连。在训练过程中，我们首先正向传播输入信号，然后根据输出和实际值计算损失，最后通过反向传播算法来更新权重，以此循环直至模型训练完成。

#### 梯度消失（Gradient Vanish）/梯度爆炸（Gradient Explode） 问题

在深度神经网络中，梯度消失和梯度爆炸是一个常见的问题。这是因为在反向传播过程中，梯度会随着层数的增加而指数级的减小或增大。

举个例子，考虑 Sigmoid 函数的导数：

$$
\begin{aligned}
\sigma(x)&=\frac{1}{1+e^{-x}}\\
\sigma'(x)&=\sigma(x)(1-\sigma(x))
\end{aligned}
$$

在 Sigmoid 函数的导数中，当 $x$ 趋近于正无穷或负无穷时，$\sigma'(x)$ 趋近于 0。这就是梯度消失的原因。当梯度消失时，网络的训练将变得非常困难，因为梯度会在反向传播的过程中经过这些层时变得非常小，导致网络无法学习到有效的参数。

为了解决这个问题，我们可以使用 ReLU 函数，它的导数在 $x>0$ 时为 1，这样可以避免梯度消失的问题。

#### 随机梯度下降（Stochastic Gradient Descent, SGD）

到现在为止，我们所说的梯度下降（GD）都是基于整个数据集的。然而，当数据集非常大时，计算整个数据集的梯度是非常耗时的（非常昂贵的）。

在梯度下降的基础上，后来提出的随机梯度下降是一种更高效的优化方法。它不是在整个数据集上计算梯度，而是在每次迭代中**随机选择一批数据（mini-batch）来计算梯度**。

为什么可以这么做？原因如下：

$$
\mathbb{E}[\nabla l_{t_i}(x)] = \mathbb{E}[\nabla f(x)] = \frac{1}{n} \sum_{i} \nabla l_i(x)
$$

这里：

-   $l_i(x)$ 是第 $i$ 个数据点的损失函数
-   $f(x)$ 是整个数据集上的目标函数
-   $\nabla l_i(x)$ 是第 $i$ 个数据点的梯度
-   $\nabla f(x)$ 是整个数据集上目标函数的真实梯度
-   $n$ 是数据集的大小
-   $t_i$ 是随机选择的数据点

这个公式说明，对于随机选择的数据点 $t_i$ 的梯度 $\nabla l_{t_i}(x)$ 的期望（即平均情况下的值）与整个数据集上目标函数 $f(x)$ 的真实梯度 $\nabla f(x)$ 的期望是相等的。但是基于无偏估计（下降方向是对真实梯度方向的无偏估计）的假设，我们可以用它来近似真实梯度。

进一步的，为了充分利用硬件资源、减少单样本采样导致的抖动，我们选取通过一批数据计算均值，再以此均值作为（估计的）梯度下降的方向，这一方法称为小批量随机梯度下降，这同样是一个无偏的近似，还降低了方差（减少了抖动）。

$$
\begin{aligned}
\mathbf{x}_t=\mathbf{x}_{t-1}-\frac{\eta_t}{b}\sum_{i\in I_t}\nabla\ell_i(\mathbf{x}_{t-1})\\
\mathbb{E}[\frac1b\sum_{i\in I_t}\nabla\ell_i(\mathbf{x})]=\nabla f(\mathbf{x})
\end{aligned}
$$

这里：

-   $\mathbf{x}_t$ 是第 $t$ 次迭代的参数
-   $\mathbf{x}_{t-1}$ 是第 $t-1$ 次迭代的参数
-   $\eta_t$ 是学习率
-   $b$ 是批大小，等于 $|I_t|$
-   $I_t$ 是第 $t$ 次迭代的数据索引集合，是在时间 $t$ 时随机选择的的一个子集。

这一批数据的大小称为批大小（batch size），通常是 32、64 或 128。这样，我们可以在每次迭代中更快地计算梯度，从而加速训练过程（相较于喂入整个数据集，也即一次完整的跑一个 epoch）。

通过多次更新参数，mini-batch 可以覆盖整个训练数据集，一个 **epoch** 则被称为覆盖一次整个训练数据集。

> 后续还会学到，我们可以在此基础上做 batch normalization 来加速训练、减少对初始化的依赖。
>
> 当然，SGD 也有它的缺点，比如可能会陷入局部最优解等等，我们会在后文中介绍其他的 SGD 变种，如 RMSprop、Adam 等。

#### 学习率调度

学习率是梯度下降算法中的一个重要超参数，它决定了参数更新的速度。学习率太大会导致参数更新过快，从而错过最优解；学习率太小会导致参数更新过慢，从而训练时间过长。

为了解决这个问题，我们可以使用学习率调度（learning rate schedule）来动态调整学习率。学习率调度可以根据训练过程中的不同阶段来调整学习率，例如每隔一定的 epoch 或当损失函数不再下降时。

学习率调度的常见方法有：

##### RMSprop

RMSprop 是一种自适应学习率方法。公式如下：

$$
v_{t} = \beta v_{t-1} + (1 - \beta)\nabla_{\theta}J(\theta)^2
$$

其中，$v_t$是梯度平方的指数移动平均，$\beta$是衰减率，用于控制历史信息保留的多少，$\nabla_{\theta}J(\theta)$是当前梯度，$J(\theta)$是损失函数。RMSprop 通过除以$v_t$来调整每一步的学习率，使得学习率逐渐减小。

在获得 $v_t$ 后，我们以如下式子对参数进行更新：

$$
\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{v_t + \epsilon}} \cdot \nabla_{\theta}J(\theta)
$$

##### Adagrad

Adagrad 方法会针对每个参数调整学习率。公式如下：

$$
\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{G_t + \epsilon}} \cdot \nabla_{\theta}J(\theta)
$$

$G_t$是到目前为止所有梯度平方的累加，$\eta$是学习率，$\epsilon$是一个很小的数，防止分母为零。Adagrad 通过$G_t$来调整每个参数的学习步长，对于出现频率高的特征，学习率会降低。

##### Adam

Adam 结合了 Momentum 和 RMSprop 的思想。公式如下：

$$
\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\hat{v}_t} + \epsilon} \cdot \hat{m}_t
$$

$\hat{m}_t$是梯度的一阶矩估计（均值），$\hat{v}_t$是二阶矩估计（未开根号的方差），$\eta$是学习率。Adam 通过计算矩估计来调整学习率，使其更稳定和快速。

##### AMSGrad

AMSGrad 是对 Adam 的改进，以防止学习率过快下降。公式如下：

$$
v_{t}^{hat} = max(v_{t-1}^{hat}, v_t)
$$

$v_{t}^{hat}$是修正后的二阶矩估计。AMSGrad 通过取之前所有时刻$v_t$的最大值来更新$v_{t}^{hat}$，确保学习率不会因为$v_t$的减小而减小。

##### AdaBound

AdaBound 也是对 Adam 的改进，旨在控制学习率的边界。公式如下：

$$
\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{v_t} + \epsilon} \cdot m_t
$$

AdaBound 通过限制学习率的变化，使其在一定范围内动态变化，促进训练过程的稳定性。
